name: Data Pipeline

on:
# push:
#    branches:
#      - main  
  workflow_dispatch:  
#  schedule:
#  - cron: '0 17 * * *' # 1:00 AM MALAYSIA TIME  
   
permissions:
  contents: write 

jobs:
  data_pipeline:
    runs-on: ubuntu-20.04

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install System-Level Dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y \
            build-essential \
            g++ \
            gcc \
            swig \
            cmake \
            python3-dev \
            python3-pip \
            libopenblas-dev \
            liblapack-dev \
            libatlas-base-dev \
            libffi-dev \
            libssl-dev \
            zlib1g-dev \
            libcurl4-openssl-dev \
            libhdf5-dev \
            libgfortran5 \
            libgomp1
  
      - name: Upgrade Python Tools
        run: |
          python3 -m pip install --upgrade pip setuptools wheel
      
      - name: Clear and Install Core ML Libraries
        run: |
          echo "üîç Installing core ML libraries..."
          pip cache purge  # Clears existing cached packages to avoid conflicts
          pip install --upgrade --use-deprecated=legacy-resolver --no-cache-dir -r requirements_linux.txt --verbose
      
      
      - name: Check for Dependency Conflicts
        run: |
          python3 -m pip check || exit 1

      - name: Debug Installed Packages
        run: |
          echo "üîç Listing installed pip packages..."
          python3 -m pip list
      
  
      - name: Check Dependency Tree
        run: |
          python3 -m pip install pipdeptree
          pipdeptree
    
      - name: Set AWS credentials
        run: |
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_DEFAULT_REGION=us-east-1" >> $GITHUB_ENV

      - name: Verify file existence and content
        run: |
          if [ -f "data/demand/2025.csv" ]; then
            echo "File exists:"
            ls -l data/demand/2025.csv
            if [ -s "data/demand/2025.csv" ]; then
              echo "CSV file has content:"
              cat data/demand/2025.csv
            else
              echo "CSV file is empty. Exiting pipeline."
              exit 1
            fi
          else
            echo "CSV file does not exist. Exiting pipeline."
            exit 1
          fi

      - name: Run data pipeline script
        run: python3 scripts/pipe_data.py
        env:
          PYTHONUNBUFFERED: 1
          LOG_LEVEL: DEBUG
          
      - name: Debug Training Script Logs
        if: failure()
        run: |
          echo "‚ö†Ô∏è Command failed. Debugging..."
          tail -n 50 /var/log/syslog || echo "No syslog available."

      - name: Commit and push updated CSV
        run: |
          git config --local user.name "GitHub Actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git add --force data/demand/2025.csv
          git commit -m "Update CSV with new data at $(date -u '+%Y-%m-%d %H:%M:%S') UTC" || echo "Nothing to commit."
          git push || echo "No changes pushed."

      - name: Notify Completion
        if: always()
        run: |
            if [ $? -eq 0 ]; then
              echo "üéâ Workflow completed successfully!"
            else
              echo "‚ùå Workflow failed. Check logs for details."
            fi
    
